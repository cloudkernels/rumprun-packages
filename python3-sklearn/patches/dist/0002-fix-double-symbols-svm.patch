diff -urN build/sklearn/svm/liblinear.pxd svm/liblinear.pxd
--- a/sklearn/svm/liblinear.pxd	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/liblinear.pxd	2019-11-14 11:09:56.174111017 -0600
@@ -29,16 +29,16 @@
     void destroy_param (parameter *)
 
 cdef extern from "liblinear_helper.c":
-    void copy_w(void *, model *, int)
-    parameter *set_parameter(int, double, double, int, char *, char *, int, int, double)
-    problem *set_problem (char *, char *, np.npy_intp *, double, char *)
-    problem *csr_set_problem (char *values, np.npy_intp *n_indices,
+    void liblinear_copy_w(void *, model *, int)
+    parameter *liblinear_set_parameter(int, double, double, int, char *, char *, int, int, double)
+    problem *liblinear_set_problem (char *, char *, np.npy_intp *, double, char *)
+    problem *liblinear_csr_set_problem (char *values, np.npy_intp *n_indices,
         char *indices, np.npy_intp *n_indptr, char *indptr, char *Y,
         np.npy_intp n_features, double bias, char *)
 
-    model *set_model(parameter *, char *, np.npy_intp *, char *, double)
+    model *liblinear_set_model(parameter *, char *, np.npy_intp *, char *, double)
 
-    double get_bias(model *)
-    void free_problem (problem *)
-    void free_parameter (parameter *)
-    void set_verbosity(int)
+    double liblinear_get_bias(model *)
+    void liblinear_free_problem (problem *)
+    void liblinear_free_parameter (parameter *)
+    void liblinear_set_verbosity(int)
diff -urN build/sklearn/svm/liblinear.pyx svm/liblinear.pyx
--- a/sklearn/svm/liblinear.pyx	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/liblinear.pyx	2019-11-14 11:16:28.738993344 -0600
@@ -24,7 +24,7 @@
     cdef int len_w
 
     if is_sparse:
-        problem = csr_set_problem(
+        problem = liblinear_csr_set_problem(
                 (<np.ndarray[np.float64_t, ndim=1, mode='c']>X.data).data,
                 (<np.ndarray[np.int32_t,   ndim=1, mode='c']>X.indices).shape,
                 (<np.ndarray[np.int32_t,   ndim=1, mode='c']>X.indices).data,
@@ -33,7 +33,7 @@
                 Y.data, (<np.int32_t>X.shape[1]), bias,
                 sample_weight.data)
     else:
-        problem = set_problem(
+        problem = liblinear_set_problem(
                 (<np.ndarray[np.float64_t, ndim=2, mode='c']>X).data,
                 Y.data,
                 (<np.ndarray[np.float64_t, ndim=2, mode='c']>X).shape,
@@ -41,14 +41,14 @@
 
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] \
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.intc)
-    param = set_parameter(solver_type, eps, C, class_weight.shape[0],
+    param = liblinear_set_parameter(solver_type, eps, C, class_weight.shape[0],
                           class_weight_label.data, class_weight.data,
                           max_iter, random_seed, epsilon)
 
     error_msg = check_parameter(problem, param)
     if error_msg:
-        free_problem(problem)
-        free_parameter(param)
+        liblinear_free_problem(problem)
+        liblinear_free_parameter(param)
         raise ValueError(error_msg)
     
     cdef BlasFunctions blas_functions
@@ -75,16 +75,16 @@
     if bias > 0: nr_feature = nr_feature + 1
     if nr_class == 2 and solver_type != 4:  # solver is not Crammer-Singer
         w = np.empty((1, nr_feature),order='F')
-        copy_w(w.data, model, nr_feature)
+        liblinear_copy_w(w.data, model, nr_feature)
     else:
         len_w = (nr_class) * nr_feature
         w = np.empty((nr_class, nr_feature),order='F')
-        copy_w(w.data, model, len_w)
+        liblinear_copy_w(w.data, model, len_w)
 
     ### FREE
     free_and_destroy_model(&model)
-    free_problem(problem)
-    free_parameter(param)
+    liblinear_free_problem(problem)
+    liblinear_free_parameter(param)
     # destroy_param(param)  don't call this or it will destroy class_weight_label and class_weight
 
     return w, n_iter
@@ -94,4 +94,4 @@
     """
     Control verbosity of libsvm library
     """
-    set_verbosity(verbosity)
+    liblinear_set_verbosity(verbosity)
diff -urN build/sklearn/svm/libsvm.pxd svm/libsvm.pxd
--- a/sklearn/svm/libsvm.pxd	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/libsvm.pxd	2019-11-14 11:14:15.270693403 -0600
@@ -41,29 +41,29 @@
 
 cdef extern from "libsvm_helper.c":
     # this file contains methods for accessing libsvm 'hidden' fields
-    svm_node **dense_to_sparse (char *, np.npy_intp *)
-    void set_parameter (svm_parameter *, int , int , int , double, double ,
+    svm_node **libsvm_dense_to_sparse (char *, np.npy_intp *)
+    void libsvm_set_parameter (svm_parameter *, int , int , int , double, double ,
                                   double , double , double , double,
                                   double, int, int, int, char *, char *, int,
                                   int)
-    void set_problem (svm_problem *, char *, char *, char *, np.npy_intp *, int)
+    void libsvm_set_problem (svm_problem *, char *, char *, char *, np.npy_intp *, int)
 
-    svm_model *set_model (svm_parameter *, int, char *, np.npy_intp *,
+    svm_model *libsvm_set_model (svm_parameter *, int, char *, np.npy_intp *,
                          char *, np.npy_intp *, np.npy_intp *, char *,
                          char *, char *, char *, char *)
 
-    void copy_sv_coef   (char *, svm_model *)
-    void copy_intercept (char *, svm_model *, np.npy_intp *)
-    void copy_SV        (char *, svm_model *, np.npy_intp *)
-    int copy_support (char *data, svm_model *model)
-    int copy_predict (char *, svm_model *, np.npy_intp *, char *) nogil
-    int copy_predict_proba (char *, svm_model *, np.npy_intp *, char *) nogil
-    int copy_predict_values(char *, svm_model *, np.npy_intp *, char *, int) nogil
-    void copy_nSV     (char *, svm_model *)
-    void copy_probA   (char *, svm_model *, np.npy_intp *)
-    void copy_probB   (char *, svm_model *, np.npy_intp *)
-    np.npy_intp  get_l  (svm_model *)
-    np.npy_intp  get_nr (svm_model *)
-    int  free_problem   (svm_problem *)
-    int  free_model     (svm_model *)
-    void set_verbosity(int)
+    void libsvm_copy_sv_coef   (char *, svm_model *)
+    void libsvm_copy_intercept (char *, svm_model *, np.npy_intp *)
+    void libsvm_copy_SV        (char *, svm_model *, np.npy_intp *)
+    int libsvm_copy_support (char *data, svm_model *model)
+    int libsvm_copy_predict (char *, svm_model *, np.npy_intp *, char *) nogil
+    int libsvm_copy_predict_proba (char *, svm_model *, np.npy_intp *, char *) nogil
+    int libsvm_copy_predict_values(char *, svm_model *, np.npy_intp *, char *, int) nogil
+    void libsvm_copy_nSV     (char *, svm_model *)
+    void libsvm_copy_probA   (char *, svm_model *, np.npy_intp *)
+    void libsvm_copy_probB   (char *, svm_model *, np.npy_intp *)
+    np.npy_intp  libsvm_get_l  (svm_model *)
+    np.npy_intp  libsvm_get_nr (svm_model *)
+    int  libsvm_free_problem   (svm_problem *)
+    int  libsvm_free_model     (svm_model *)
+    void libsvm_set_verbosity(int)
diff -urN build/sklearn/svm/libsvm_sparse.pyx svm/libsvm_sparse.pyx
--- a/sklearn/svm/libsvm_sparse.pyx	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/libsvm_sparse.pyx	2019-11-14 11:27:40.456644077 -0600
@@ -22,47 +22,47 @@
 
 cdef extern from "libsvm_sparse_helper.c":
     # this file contains methods for accessing libsvm 'hidden' fields
-    svm_csr_problem * csr_set_problem (char *, np.npy_intp *,
+    svm_csr_problem * libsvmsp_csr_set_problem (char *, np.npy_intp *,
          char *, np.npy_intp *, char *, char *, char *, int )
-    svm_csr_model *csr_set_model(svm_parameter *param, int nr_class,
+    svm_csr_model *libsvmsp_csr_set_model(svm_parameter *param, int nr_class,
                             char *SV_data, np.npy_intp *SV_indices_dims,
                             char *SV_indices, np.npy_intp *SV_intptr_dims,
                             char *SV_intptr,
                             char *sv_coef, char *rho, char *nSV,
                             char *probA, char *probB)
-    svm_parameter *set_parameter (int , int , int , double, double ,
+    svm_parameter *libsvmsp_set_parameter (int , int , int , double, double ,
                                   double , double , double , double,
                                   double, int, int, int, char *, char *, int,
                                   int)
-    void copy_sv_coef   (char *, svm_csr_model *)
-    void copy_support   (char *, svm_csr_model *)
-    void copy_intercept (char *, svm_csr_model *, np.npy_intp *)
-    int copy_predict (char *, svm_csr_model *, np.npy_intp *, char *)
-    int csr_copy_predict_values (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
+    void libsvmsp_copy_sv_coef   (char *, svm_csr_model *)
+    void libsvmsp_copy_support   (char *, svm_csr_model *)
+    void libsvmsp_copy_intercept (char *, svm_csr_model *, np.npy_intp *)
+    int libsvmsp_copy_predict (char *, svm_csr_model *, np.npy_intp *, char *)
+    int libsvmsp_csr_copy_predict_values (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
         	char *index, np.npy_intp *intptr_size, char *size,
                 svm_csr_model *model, char *dec_values, int nr_class)
-    int csr_copy_predict (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
+    int libsvmsp_csr_copy_predict (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
         	char *index, np.npy_intp *intptr_size, char *size,
                 svm_csr_model *model, char *dec_values) nogil
-    int csr_copy_predict_proba (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
+    int libsvmsp_csr_copy_predict_proba (np.npy_intp *data_size, char *data, np.npy_intp *index_size,
         	char *index, np.npy_intp *intptr_size, char *size,
                 svm_csr_model *model, char *dec_values) nogil
 
-    int  copy_predict_values(char *, svm_csr_model *, np.npy_intp *, char *, int)
-    int  csr_copy_SV (char *values, np.npy_intp *n_indices,
+    int  libsvmsp_copy_predict_values(char *, svm_csr_model *, np.npy_intp *, char *, int)
+    int  libsvmsp_csr_copy_SV (char *values, np.npy_intp *n_indices,
         	char *indices, np.npy_intp *n_indptr, char *indptr,
                 svm_csr_model *model, int n_features)
-    np.npy_intp get_nonzero_SV ( svm_csr_model *)
-    void copy_nSV     (char *, svm_csr_model *)
-    void copy_probA   (char *, svm_csr_model *, np.npy_intp *)
-    void copy_probB   (char *, svm_csr_model *, np.npy_intp *)
-    np.npy_intp  get_l  (svm_csr_model *)
-    np.npy_intp  get_nr (svm_csr_model *)
-    int  free_problem   (svm_csr_problem *)
-    int  free_model     (svm_csr_model *)
-    int  free_param     (svm_parameter *)
-    int free_model_SV(svm_csr_model *model)
-    void set_verbosity(int)
+    np.npy_intp libsvmsp_get_nonzero_SV ( svm_csr_model *)
+    void libsvmsp_copy_nSV     (char *, svm_csr_model *)
+    void libsvmsp_copy_probA   (char *, svm_csr_model *, np.npy_intp *)
+    void libsvmsp_copy_probB   (char *, svm_csr_model *, np.npy_intp *)
+    np.npy_intp  libsvmsp_get_l  (svm_csr_model *)
+    np.npy_intp  libsvmsp_get_nr (svm_csr_model *)
+    int  libsvmsp_free_problem   (svm_csr_problem *)
+    int  libsvmsp_free_model     (svm_csr_model *)
+    int  libsvmsp_free_param     (svm_parameter *)
+    int libsvmsp_free_model_SV(svm_csr_model *model)
+    void libsvmsp_set_verbosity(int)
 
 
 np.import_array()
@@ -121,7 +121,7 @@
     assert(kernel_type != 4)
 
     # set libsvm problem
-    problem = csr_set_problem(values.data, indices.shape, indices.data,
+    problem = libsvmsp_csr_set_problem(values.data, indices.shape, indices.data,
                               indptr.shape, indptr.data, Y.data,
                               sample_weight.data, kernel_type)
 
@@ -129,7 +129,7 @@
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
 
     # set parameters
-    param = set_parameter(svm_type, kernel_type, degree, gamma, coef0,
+    param = libsvmsp_set_parameter(svm_type, kernel_type, degree, gamma, coef0,
                           nu, cache_size, C, eps, p, shrinking,
                           probability, <int> class_weight.shape[0],
                           class_weight_label.data, class_weight.data, max_iter,
@@ -140,8 +140,8 @@
         raise MemoryError("Seems we've run out of memory")
     error_msg = svm_csr_check_parameter(problem, param);
     if error_msg:
-        free_problem(problem)
-        free_param(param)
+        libsvmsp_free_problem(problem)
+        libsvmsp_free_param(param)
         raise ValueError(error_msg)
 
     # call svm_train, this does the real work
@@ -149,37 +149,37 @@
     with nogil:
         model = svm_csr_train(problem, param, &fit_status)
 
-    cdef np.npy_intp SV_len = get_l(model)
-    cdef np.npy_intp n_class = get_nr(model)
+    cdef np.npy_intp SV_len = libsvmsp_get_l(model)
+    cdef np.npy_intp n_class = libsvmsp_get_nr(model)
 
     # copy model.sv_coef
     # we create a new array instead of resizing, otherwise
     # it would not erase previous information
     cdef np.ndarray sv_coef_data
     sv_coef_data = np.empty((n_class-1)*SV_len, dtype=np.float64)
-    copy_sv_coef (sv_coef_data.data, model)
+    libsvmsp_copy_sv_coef (sv_coef_data.data, model)
 
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] support
     support = np.empty(SV_len, dtype=np.int32)
-    copy_support(support.data, model)
+    libsvmsp_copy_support(support.data, model)
 
     # copy model.rho into the intercept
     # the intercept is just model.rho but with sign changed
     cdef np.ndarray intercept
     intercept = np.empty(n_class*(n_class-1)//2, dtype=np.float64)
-    copy_intercept (intercept.data, model, intercept.shape)
+    libsvmsp_copy_intercept (intercept.data, model, intercept.shape)
 
     # copy model.SV
     # we erase any previous information in SV
     # TODO: custom kernel
     cdef np.npy_intp nonzero_SV
-    nonzero_SV = get_nonzero_SV (model)
+    nonzero_SV = libsvmsp_get_nonzero_SV (model)
 
     cdef np.ndarray SV_data, SV_indices, SV_indptr
     SV_data = np.empty(nonzero_SV, dtype=np.float64)
     SV_indices = np.empty(nonzero_SV, dtype=np.int32)
     SV_indptr = np.empty(<np.npy_intp>SV_len + 1, dtype=np.int32)
-    csr_copy_SV(SV_data.data, SV_indices.shape, SV_indices.data,
+    libsvmsp_csr_copy_SV(SV_data.data, SV_indices.shape, SV_indices.data,
                 SV_indptr.shape, SV_indptr.data, model, n_features)
     support_vectors_ = sparse.csr_matrix(
 	(SV_data, SV_indices, SV_indptr), (SV_len, n_features))
@@ -188,7 +188,7 @@
     # TODO: do only in classification
     cdef np.ndarray n_class_SV 
     n_class_SV = np.empty(n_class, dtype=np.int32)
-    copy_nSV(n_class_SV.data, model)
+    libsvmsp_copy_nSV(n_class_SV.data, model)
 
     # # copy probabilities
     cdef np.ndarray probA, probB
@@ -196,18 +196,18 @@
         if svm_type < 2: # SVC and NuSVC
             probA = np.empty(n_class*(n_class-1)//2, dtype=np.float64)
             probB = np.empty(n_class*(n_class-1)//2, dtype=np.float64)
-            copy_probB(probB.data, model, probB.shape)
+            libsvmsp_copy_probB(probB.data, model, probB.shape)
         else:
             probA = np.empty(1, dtype=np.float64)
             probB = np.empty(0, dtype=np.float64)
-        copy_probA(probA.data, model, probA.shape)
+        libsvmsp_copy_probA(probA.data, model, probA.shape)
     else:
         probA = np.empty(0, dtype=np.float64)
         probB = np.empty(0, dtype=np.float64)
 
     svm_csr_free_and_destroy_model (&model)
-    free_problem(problem)
-    free_param(param)
+    libsvmsp_free_problem(problem)
+    libsvmsp_free_param(param)
 
     return (support, support_vectors_, sv_coef_data, intercept, n_class_SV,
             probA, probB, fit_status)
@@ -258,7 +258,7 @@
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] \
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
     cdef int rv
-    param = set_parameter(svm_type, kernel_type, degree, gamma,
+    param = libsvmsp_set_parameter(svm_type, kernel_type, degree, gamma,
                           coef0, nu,
                           100., # cache size has no effect on predict
                           C, eps, p, shrinking,
@@ -266,7 +266,7 @@
                           class_weight.data, -1,
                           -1) # random seed has no effect on predict either
 
-    model = csr_set_model(param, <int> nSV.shape[0], SV_data.data,
+    model = libsvmsp_csr_set_model(param, <int> nSV.shape[0], SV_data.data,
                           SV_indices.shape, SV_indices.data,
                           SV_indptr.shape, SV_indptr.data,
                           sv_coef.data, intercept.data,
@@ -274,16 +274,16 @@
     #TODO: use check_model
     dec_values = np.empty(T_indptr.shape[0]-1)
     with nogil:
-        rv = csr_copy_predict(T_data.shape, T_data.data,
+        rv = libsvmsp_csr_copy_predict(T_data.shape, T_data.data,
                               T_indices.shape, T_indices.data,
                               T_indptr.shape, T_indptr.data,
                               model, dec_values.data)
     if rv < 0:
         raise MemoryError("We've run out of memory")
     # free model and param
-    free_model_SV(model)
-    free_model(model)
-    free_param(param)
+    libsvmsp_free_model_SV(model)
+    libsvmsp_free_model(model)
+    libsvmsp_free_param(param)
     return dec_values
 
 
@@ -312,7 +312,7 @@
     cdef svm_csr_model *model
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] \
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
-    param = set_parameter(svm_type, kernel_type, degree, gamma,
+    param = libsvmsp_set_parameter(svm_type, kernel_type, degree, gamma,
                           coef0, nu,
                           100., # cache size has no effect on predict
                           C, eps, p, shrinking,
@@ -320,26 +320,26 @@
                           class_weight.data, -1,
                           -1) # random seed has no effect on predict either
 
-    model = csr_set_model(param, <int> nSV.shape[0], SV_data.data,
+    model = libsvmsp_csr_set_model(param, <int> nSV.shape[0], SV_data.data,
                           SV_indices.shape, SV_indices.data,
                           SV_indptr.shape, SV_indptr.data,
                           sv_coef.data, intercept.data,
                           nSV.data, probA.data, probB.data)
     #TODO: use check_model
-    cdef np.npy_intp n_class = get_nr(model)
+    cdef np.npy_intp n_class = libsvmsp_get_nr(model)
     cdef int rv
     dec_values = np.empty((T_indptr.shape[0]-1, n_class), dtype=np.float64)
     with nogil:
-        rv = csr_copy_predict_proba(T_data.shape, T_data.data,
+        rv = libsvmsp_csr_copy_predict_proba(T_data.shape, T_data.data,
                                     T_indices.shape, T_indices.data,
                                     T_indptr.shape, T_indptr.data,
                                     model, dec_values.data)
     if rv < 0:
         raise MemoryError("We've run out of memory")
     # free model and param
-    free_model_SV(model)
-    free_model(model)
-    free_param(param)
+    libsvmsp_free_model_SV(model)
+    libsvmsp_free_model(model)
+    libsvmsp_free_param(param)
     return dec_values
 
 
@@ -375,14 +375,14 @@
     cdef svm_csr_model *model
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] \
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
-    param = set_parameter(svm_type, kernel_type, degree, gamma,
+    param = libsvmsp_set_parameter(svm_type, kernel_type, degree, gamma,
                           coef0, nu,
                           100., # cache size has no effect on predict
                           C, eps, p, shrinking,
                           probability, <int> class_weight.shape[0],
                           class_weight_label.data, class_weight.data, -1, -1)
 
-    model = csr_set_model(param, <int> nSV.shape[0], SV_data.data,
+    model = libsvmsp_csr_set_model(param, <int> nSV.shape[0], SV_data.data,
                           SV_indices.shape, SV_indices.data,
                           SV_indptr.shape, SV_indptr.data,
                           sv_coef.data, intercept.data,
@@ -391,19 +391,19 @@
     if svm_type > 1:
         n_class = 1
     else:
-        n_class = get_nr(model)
+        n_class = libsvmsp_get_nr(model)
         n_class = n_class * (n_class - 1) // 2
 
     dec_values = np.empty((T_indptr.shape[0] - 1, n_class), dtype=np.float64)
-    if csr_copy_predict_values(T_data.shape, T_data.data,
+    if libsvmsp_csr_copy_predict_values(T_data.shape, T_data.data,
                         T_indices.shape, T_indices.data,
                         T_indptr.shape, T_indptr.data,
                         model, dec_values.data, n_class) < 0:
         raise MemoryError("We've run out of memory")
     # free model and param
-    free_model_SV(model)
-    free_model(model)
-    free_param(param)
+    libsvmsp_free_model_SV(model)
+    libsvmsp_free_model(model)
+    libsvmsp_free_param(param)
 
     return dec_values
 
@@ -412,4 +412,4 @@
     """
     Control verbosity of libsvm library
     """
-    set_verbosity(verbosity)
+    libsvmsp_set_verbosity(verbosity)
diff -urN build/sklearn/svm/src/libsvm/libsvm_helper.c svm/src/libsvm/libsvm_helper.c
--- a/sklearn/svm/src/libsvm/libsvm_helper.c	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/src/libsvm/libsvm_helper.c	2019-11-14 10:59:52.864754244 -0600
@@ -55,7 +55,7 @@
 /*
  * Fill an svm_parameter struct.
  */
-void set_parameter(struct svm_parameter *param, int svm_type, int kernel_type, int degree,
+void libsvm_set_parameter(struct svm_parameter *param, int svm_type, int kernel_type, int degree,
 		double gamma, double coef0, double nu, double cache_size, double C,
 		double eps, double p, int shrinking, int probability, int nr_weight,
 		char *weight_label, char *weight, int max_iter, int random_seed)
@@ -82,7 +82,7 @@
 /*
  * Fill an svm_problem struct. problem->x will be malloc'd.
  */
-void set_problem(struct svm_problem *problem, char *X, char *Y, char *sample_weight, npy_intp *dims, int kernel_type)
+void libsvm_set_problem(struct svm_problem *problem, char *X, char *Y, char *sample_weight, npy_intp *dims, int kernel_type)
 {
     if (problem == NULL) return;
     problem->l = (int) dims[0]; /* number of samples */
@@ -104,7 +104,7 @@
  * data structure.
  *
  */
-struct svm_model *set_model(struct svm_parameter *param, int nr_class,
+struct svm_model *libsvm_set_model(struct svm_parameter *param, int nr_class,
                             char *SV, npy_intp *SV_dims,
                             char *support, npy_intp *support_dims,
                             npy_intp *sv_coef_strides,
@@ -204,7 +204,7 @@
 /*
  * Get the number of support vectors in a model.
  */
-npy_intp get_l(struct svm_model *model)
+npy_intp libsvm_get_l(struct svm_model *model)
 {
     return (npy_intp) model->l;
 }
@@ -213,7 +213,7 @@
  * Get the number of classes in a model, = 2 in regression/one class
  * svm.
  */
-npy_intp get_nr(struct svm_model *model)
+npy_intp libsvm_get_nr(struct svm_model *model)
 {
     return (npy_intp) model->nr_class;
 }
@@ -223,7 +223,7 @@
  * model->sv_coef is a double **, whereas data is just a double *,
  * so we have to do some stupid copying.
  */
-void copy_sv_coef(char *data, struct svm_model *model)
+void libsvm_copy_sv_coef(char *data, struct svm_model *model)
 {
     int i, len = model->nr_class-1;
     double *temp = (double *) data;
@@ -233,7 +233,7 @@
     }
 }
 
-void copy_intercept(char *data, struct svm_model *model, npy_intp *dims)
+void libsvm_copy_intercept(char *data, struct svm_model *model, npy_intp *dims)
 {
     /* intercept = -rho */
     npy_intp i, n = dims[0];
@@ -251,7 +251,7 @@
  * structures, so we have to do the conversion on the fly and also
  * iterate fast over data.
  */
-void copy_SV(char *data, struct svm_model *model, npy_intp *dims)
+void libsvm_copy_SV(char *data, struct svm_model *model, npy_intp *dims)
 {
     int i, n = model->l;
     double *tdata = (double *) data;
@@ -262,7 +262,7 @@
     }
 }
 
-void copy_support (char *data, struct svm_model *model)
+void libsvm_copy_support (char *data, struct svm_model *model)
 {
     memcpy (data, model->sv_ind, (model->l) * sizeof(int));
 }
@@ -271,18 +271,18 @@
  * copy svm_model.nSV, an array with the number of SV for each class
  * will be NULL in the case of SVR, OneClass
  */
-void copy_nSV(char *data, struct svm_model *model)
+void libsvm_copy_nSV(char *data, struct svm_model *model)
 {
     if (model->label == NULL) return;
     memcpy(data, model->nSV, model->nr_class * sizeof(int));
 }
 
-void copy_probA(char *data, struct svm_model *model, npy_intp * dims)
+void libsvm_copy_probA(char *data, struct svm_model *model, npy_intp * dims)
 {
     memcpy(data, model->probA, dims[0] * sizeof(double));
 }
 
-void copy_probB(char *data, struct svm_model *model, npy_intp * dims)
+void libsvm_copy_probB(char *data, struct svm_model *model, npy_intp * dims)
 {
     memcpy(data, model->probB, dims[0] * sizeof(double));
 }
@@ -292,7 +292,7 @@
  *
  *  It will return -1 if we run out of memory.
  */
-int copy_predict(char *predict, struct svm_model *model, npy_intp *predict_dims,
+int libsvm_copy_predict(char *predict, struct svm_model *model, npy_intp *predict_dims,
                  char *dec_values)
 {
     double *t = (double *) dec_values;
@@ -311,7 +311,7 @@
     return 0;
 }
 
-int copy_predict_values(char *predict, struct svm_model *model,
+int libsvm_copy_predict_values(char *predict, struct svm_model *model,
                         npy_intp *predict_dims, char *dec_values, int nr_class)
 {
     npy_intp i;
@@ -330,7 +330,7 @@
 
 
 
-int copy_predict_proba(char *predict, struct svm_model *model, npy_intp *predict_dims,
+int libsvm_copy_predict_proba(char *predict, struct svm_model *model, npy_intp *predict_dims,
                  char *dec_values)
 {
     npy_intp i, n, m;
@@ -355,7 +355,7 @@
  * correct order)
  */
 
-int free_model(struct svm_model *model)
+int libsvm_free_model(struct svm_model *model)
 {
     /* like svm_free_and_destroy_model, but does not free sv_coef[i] */
     if (model == NULL) return -1;
@@ -375,7 +375,7 @@
     return 0;
 }
 
-int free_param(struct svm_parameter *param)
+int libsvm_free_param(struct svm_parameter *param)
 {
     if (param == NULL) return -1;
     free(param);
@@ -393,7 +393,7 @@
 }
 
 /* provide convenience wrapper */
-void set_verbosity(int verbosity_flag){
+void libsvm_set_verbosity(int verbosity_flag){
 	if (verbosity_flag)
 		svm_set_print_string_function(&print_string_stdout);
 	else
diff -urN build/sklearn/svm/src/libsvm/libsvm_sparse_helper.c svm/src/libsvm/libsvm_sparse_helper.c
--- a/sklearn/svm/src/libsvm/libsvm_sparse_helper.c	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/src/libsvm/libsvm_sparse_helper.c	2019-11-14 11:04:13.693340940 -0600
@@ -41,7 +41,7 @@
 
 
 
-struct svm_parameter * set_parameter(int svm_type, int kernel_type, int degree,
+struct svm_parameter * libsvmsp_set_parameter(int svm_type, int kernel_type, int degree,
 		double gamma, double coef0, double nu, double cache_size, double C,
 		double eps, double p, int shrinking, int probability, int nr_weight,
 		char *weight_label, char *weight, int max_iter, int random_seed)
@@ -76,7 +76,7 @@
  *
  * TODO: precomputed kernel.
  */
-struct svm_csr_problem * csr_set_problem (char *values, npy_intp *n_indices,
+struct svm_csr_problem * libsvmsp_csr_set_problem (char *values, npy_intp *n_indices,
 		char *indices, npy_intp *n_indptr, char *indptr, char *Y,
                 char *sample_weight, int kernel_type) {
 
@@ -98,7 +98,7 @@
 }
 
 
-struct svm_csr_model *csr_set_model(struct svm_parameter *param, int nr_class,
+struct svm_csr_model *libsvmsp_csr_set_model(struct svm_parameter *param, int nr_class,
                             char *SV_data, npy_intp *SV_indices_dims,
                             char *SV_indices, npy_intp *SV_indptr_dims,
                             char *SV_intptr,
@@ -203,7 +203,7 @@
 /*
  * Copy support vectors into a scipy.sparse.csr matrix
  */
-int csr_copy_SV (char *data, npy_intp *n_indices,
+int libsvmsp_csr_copy_SV (char *data, npy_intp *n_indices,
 		char *indices, npy_intp *n_indptr, char *indptr,
 		struct svm_csr_model *model, int n_features)
 {
@@ -227,7 +227,7 @@
 }
 
 /* get number of nonzero coefficients in support vectors */
-npy_intp get_nonzero_SV (struct svm_csr_model *model) {
+npy_intp libsvmsp_get_nonzero_SV (struct svm_csr_model *model) {
 	int i, j;
 	npy_intp count=0;
 	for (i=0; i<model->l; ++i) {
@@ -244,7 +244,7 @@
 /*
  * Predict using a model, where data is expected to be enconded into a csr matrix.
  */
-int csr_copy_predict (npy_intp *data_size, char *data, npy_intp *index_size,
+int libsvmsp_csr_copy_predict (npy_intp *data_size, char *data, npy_intp *index_size,
 		char *index, npy_intp *intptr_size, char *intptr, struct svm_csr_model *model,
 		char *dec_values) {
     double *t = (double *) dec_values;
@@ -265,7 +265,7 @@
     return 0;
 }
 
-int csr_copy_predict_values (npy_intp *data_size, char *data, npy_intp *index_size,
+int libsvmsp_csr_copy_predict_values (npy_intp *data_size, char *data, npy_intp *index_size,
                 char *index, npy_intp *intptr_size, char *intptr, struct svm_csr_model *model,
                 char *dec_values, int nr_class) {
     struct svm_csr_node **predict_nodes;
@@ -286,7 +286,7 @@
     return 0;
 }
 
-int csr_copy_predict_proba (npy_intp *data_size, char *data, npy_intp *index_size,
+int libsvmsp_csr_copy_predict_proba (npy_intp *data_size, char *data, npy_intp *index_size,
 		char *index, npy_intp *intptr_size, char *intptr, struct svm_csr_model *model,
 		char *dec_values) {
 
@@ -309,12 +309,12 @@
 }
 
 
-npy_intp get_nr(struct svm_csr_model *model)
+npy_intp libsvmsp_get_nr(struct svm_csr_model *model)
 {
     return (npy_intp) model->nr_class;
 }
 
-void copy_intercept(char *data, struct svm_csr_model *model, npy_intp *dims)
+void libsvmsp_copy_intercept(char *data, struct svm_csr_model *model, npy_intp *dims)
 {
     /* intercept = -rho */
     npy_intp i, n = dims[0];
@@ -327,7 +327,7 @@
     }
 }
 
-void copy_support (char *data, struct svm_csr_model *model)
+void libsvmsp_copy_support (char *data, struct svm_csr_model *model)
 {
     memcpy (data, model->sv_ind, (model->l) * sizeof(int));
 }
@@ -337,7 +337,7 @@
  * model->sv_coef is a double **, whereas data is just a double *,
  * so we have to do some stupid copying.
  */
-void copy_sv_coef(char *data, struct svm_csr_model *model)
+void libsvmsp_copy_sv_coef(char *data, struct svm_csr_model *model)
 {
     int i, len = model->nr_class-1;
     double *temp = (double *) data;
@@ -350,12 +350,12 @@
 /*
  * Get the number of support vectors in a model.
  */
-npy_intp get_l(struct svm_csr_model *model)
+npy_intp libsvmsp_get_l(struct svm_csr_model *model)
 {
     return (npy_intp) model->l;
 }
 
-void copy_nSV(char *data, struct svm_csr_model *model)
+void libsvmsp_copy_nSV(char *data, struct svm_csr_model *model)
 {
     if (model->label == NULL) return;
     memcpy(data, model->nSV, model->nr_class * sizeof(int));
@@ -365,18 +365,18 @@
  * same as above with model->label
  * TODO: merge in the cython layer
  */
-void copy_label(char *data, struct svm_csr_model *model)
+void libsvmsp_copy_label(char *data, struct svm_csr_model *model)
 {
     if (model->label == NULL) return;
     memcpy(data, model->label, model->nr_class * sizeof(int));
 }
 
-void copy_probA(char *data, struct svm_csr_model *model, npy_intp * dims)
+void libsvmsp_copy_probA(char *data, struct svm_csr_model *model, npy_intp * dims)
 {
     memcpy(data, model->probA, dims[0] * sizeof(double));
 }
 
-void copy_probB(char *data, struct svm_csr_model *model, npy_intp * dims)
+void libsvmsp_copy_probB(char *data, struct svm_csr_model *model, npy_intp * dims)
 {
     memcpy(data, model->probB, dims[0] * sizeof(double));
 }
@@ -387,7 +387,7 @@
  * sharing happens across objects (they *must* be called in the
  * correct order)
  */
-int free_problem(struct svm_csr_problem *problem)
+int libsvmsp_free_problem(struct svm_csr_problem *problem)
 {
     int i;
     if (problem == NULL) return -1;
@@ -398,7 +398,7 @@
     return 0;
 }
 
-int free_model(struct svm_csr_model *model)
+int libsvmsp_free_model(struct svm_csr_model *model)
 {
     /* like svm_free_and_destroy_model, but does not free sv_coef[i] */
     if (model == NULL) return -1;
@@ -414,7 +414,7 @@
     return 0;
 }
 
-int free_param(struct svm_parameter *param)
+int libsvmsp_free_param(struct svm_parameter *param)
 {
     if (param == NULL) return -1;
     free(param);
@@ -422,7 +422,7 @@
 }
 
 
-int free_model_SV(struct svm_csr_model *model)
+int libsvmsp_free_model_SV(struct svm_csr_model *model)
 {
     int i;
     for (i=model->l-1; i>=0; --i) free(model->SV[i]);
@@ -443,7 +443,7 @@
 }
 
 /* provide convenience wrapper */
-void set_verbosity(int verbosity_flag){
+void libsvmsp_set_verbosity(int verbosity_flag){
 	if (verbosity_flag)
 		svm_set_print_string_function(&print_string_stdout);
 	else
--- a/sklearn/svm/libsvm.pyx	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/libsvm.pyx	2019-11-14 11:45:42.343262775 -0600
@@ -168,13 +168,13 @@
                (sample_weight.shape[0], X.shape[0])
 
     kernel_index = LIBSVM_KERNEL_TYPES.index(kernel)
-    set_problem(
+    libsvm_set_problem(
         &problem, X.data, Y.data, sample_weight.data, X.shape, kernel_index)
     if problem.x == NULL:
         raise MemoryError("Seems we've run out of memory")
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] \
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
-    set_parameter(
+    libsvm_set_parameter(
         &param, svm_type, kernel_index, degree, gamma, coef0, nu, cache_size,
         C, tol, epsilon, shrinking, probability, <int> class_weight.shape[0],
         class_weight_label.data, class_weight.data, max_iter, random_seed)
@@ -192,21 +192,21 @@
 
     # from here until the end, we just copy the data returned by
     # svm_train
-    SV_len  = get_l(model)
-    n_class = get_nr(model)
+    SV_len  = libsvm_get_l(model)
+    n_class = libsvm_get_nr(model)
 
     cdef np.ndarray[np.float64_t, ndim=2, mode='c'] sv_coef
     sv_coef = np.empty((n_class-1, SV_len), dtype=np.float64)
-    copy_sv_coef (sv_coef.data, model)
+    libsvm_copy_sv_coef (sv_coef.data, model)
 
     # the intercept is just model.rho but with sign changed
     cdef np.ndarray[np.float64_t, ndim=1, mode='c'] intercept
     intercept = np.empty(int((n_class*(n_class-1))/2), dtype=np.float64)
-    copy_intercept (intercept.data, model, intercept.shape)
+    libsvm_copy_intercept (intercept.data, model, intercept.shape)
 
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] support
     support = np.empty (SV_len, dtype=np.int32)
-    copy_support (support.data, model)
+    libsvm_copy_support (support.data, model)
 
     # copy model.SV
     cdef np.ndarray[np.float64_t, ndim=2, mode='c'] support_vectors
@@ -215,12 +215,12 @@
         support_vectors = np.empty((0, 0), dtype=np.float64)
     else:
         support_vectors = np.empty((SV_len, X.shape[1]), dtype=np.float64)
-        copy_SV(support_vectors.data, model, support_vectors.shape)
+        libsvm_copy_SV(support_vectors.data, model, support_vectors.shape)
 
     # TODO: do only in classification
     cdef np.ndarray[np.int32_t, ndim=1, mode='c'] n_class_SV
     n_class_SV = np.empty(n_class, dtype=np.int32)
-    copy_nSV(n_class_SV.data, model)
+    libsvm_copy_nSV(n_class_SV.data, model)
 
     cdef np.ndarray[np.float64_t, ndim=1, mode='c'] probA
     cdef np.ndarray[np.float64_t, ndim=1, mode='c'] probB
@@ -228,11 +228,11 @@
         if svm_type < 2: # SVC and NuSVC
             probA = np.empty(int(n_class*(n_class-1)/2), dtype=np.float64)
             probB = np.empty(int(n_class*(n_class-1)/2), dtype=np.float64)
-            copy_probB(probB.data, model, probB.shape)
+            libsvm_copy_probB(probB.data, model, probB.shape)
         else:
             probA = np.empty(1, dtype=np.float64)
             probB = np.empty(0, dtype=np.float64)
-        copy_probA(probA.data, model, probA.shape)
+        libsvm_copy_probA(probA.data, model, probA.shape)
     else:
         probA = np.empty(0, dtype=np.float64)
         probB = np.empty(0, dtype=np.float64)
@@ -261,7 +261,7 @@
 
     kernel_index = LIBSVM_KERNEL_TYPES.index(kernel)
 
-    set_parameter(param, svm_type, kernel_index, degree, gamma, coef0, nu,
+    libsvm_set_parameter(param, svm_type, kernel_index, degree, gamma, coef0, nu,
                          cache_size, C, tol, epsilon, shrinking, probability,
                          nr_weight, weight_label, weight, max_iter, random_seed)
 
@@ -315,7 +315,7 @@
     set_predict_params(&param, svm_type, kernel, degree, gamma, coef0,
                        cache_size, 0, <int>class_weight.shape[0],
                        class_weight_label.data, class_weight.data)
-    model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
+    model = libsvm_set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
                       support.data, support.shape, sv_coef.strides,
                       sv_coef.data, intercept.data, nSV.data, probA.data, probB.data)
 
@@ -323,11 +323,11 @@
     try:
         dec_values = np.empty(X.shape[0])
         with nogil:
-            rv = copy_predict(X.data, model, X.shape, dec_values.data)
+            rv = libsvm_copy_predict(X.data, model, X.shape, dec_values.data)
         if rv < 0:
             raise MemoryError("We've run out of memory")
     finally:
-        free_model(model)
+        libsvm_free_model(model)
 
     return dec_values
 
@@ -381,20 +381,20 @@
     set_predict_params(&param, svm_type, kernel, degree, gamma, coef0,
                        cache_size, 1, <int>class_weight.shape[0],
                        class_weight_label.data, class_weight.data)
-    model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
+    model = libsvm_set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
                       support.data, support.shape, sv_coef.strides,
                       sv_coef.data, intercept.data, nSV.data,
                       probA.data, probB.data)
 
-    cdef np.npy_intp n_class = get_nr(model)
+    cdef np.npy_intp n_class = libsvm_get_nr(model)
     try:
         dec_values = np.empty((X.shape[0], n_class), dtype=np.float64)
         with nogil:
-            rv = copy_predict_proba(X.data, model, X.shape, dec_values.data)
+            rv = libsvm_copy_predict_proba(X.data, model, X.shape, dec_values.data)
         if rv < 0:
             raise MemoryError("We've run out of memory")
     finally:
-        free_model(model)
+        libsvm_free_model(model)
 
     return dec_values
 
@@ -435,7 +435,7 @@
                        cache_size, 0, <int>class_weight.shape[0],
                        class_weight_label.data, class_weight.data)
 
-    model = set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
+    model = libsvm_set_model(&param, <int> nSV.shape[0], SV.data, SV.shape,
                       support.data, support.shape, sv_coef.strides,
                       sv_coef.data, intercept.data, nSV.data,
                       probA.data, probB.data)
@@ -443,17 +443,17 @@
     if svm_type > 1:
         n_class = 1
     else:
-        n_class = get_nr(model)
+        n_class = libsvm_get_nr(model)
         n_class = n_class * (n_class - 1) // 2
 
     try:
         dec_values = np.empty((X.shape[0], n_class), dtype=np.float64)
         with nogil:
-            rv = copy_predict_values(X.data, model, X.shape, dec_values.data, n_class)
+            rv = libsvm_copy_predict_values(X.data, model, X.shape, dec_values.data, n_class)
         if rv < 0:
             raise MemoryError("We've run out of memory")
     finally:
-        free_model(model)
+        libsvm_free_model(model)
 
     return dec_values
 
@@ -540,7 +540,7 @@
 
     # set problem
     kernel_index = LIBSVM_KERNEL_TYPES.index(kernel)
-    set_problem(
+    libsvm_set_problem(
         &problem, X.data, Y.data, sample_weight.data, X.shape, kernel_index)
     if problem.x == NULL:
         raise MemoryError("Seems we've run out of memory")
@@ -548,7 +548,7 @@
         class_weight_label = np.arange(class_weight.shape[0], dtype=np.int32)
 
     # set parameters
-    set_parameter(
+    libsvm_set_parameter(
         &param, svm_type, kernel_index, degree, gamma, coef0, nu, cache_size,
         C, tol, tol, shrinking, probability, <int>
         class_weight.shape[0], class_weight_label.data,
@@ -573,4 +573,4 @@
     """
     Control verbosity of libsvm library
     """
-    set_verbosity(verbosity)
+    libsvm_set_verbosity(verbosity)
--- a/sklearn/svm/src/liblinear/liblinear_helper.c	2019-07-29 08:29:18.000000000 -0500
+++ b/sklearn/svm/src/liblinear/liblinear_helper.c	2019-11-14 12:30:30.953966929 -0600
@@ -15,7 +15,7 @@
  *
  * If bias is > 0, we append an item at the end.
  */
-static struct feature_node **dense_to_sparse(double *x, npy_intp *dims,
+static struct feature_node **liblinear_dense_to_sparse(double *x, npy_intp *dims,
                                              double bias)
 {
     struct feature_node **sparse;
@@ -82,7 +82,7 @@
 /*
  * Convert scipy.sparse.csr to libsvm's sparse data structure
  */
-static struct feature_node **csr_to_sparse(double *values,
+static struct feature_node **liblinear_csr_to_sparse(double *values,
         npy_intp *shape_indices, int *indices, npy_intp *shape_indptr,
         int *indptr, double bias, int n_features)
 {
@@ -124,7 +124,7 @@
     return sparse;
 }
 
-struct problem * set_problem(char *X,char *Y, npy_intp *dims, double bias, char* sample_weight)
+struct problem * liblinear_set_problem(char *X,char *Y, npy_intp *dims, double bias, char* sample_weight)
 {
     struct problem *problem;
     /* not performant but simple */
@@ -140,7 +140,7 @@
 
     problem->y = (double *) Y;
     problem->sample_weight = (double *) sample_weight;
-    problem->x = dense_to_sparse((double *) X, dims, bias);
+    problem->x = liblinear_dense_to_sparse((double *) X, dims, bias);
     problem->bias = bias;
     problem->sample_weight = sample_weight;
     if (problem->x == NULL) { 
@@ -151,7 +151,7 @@
     return problem;
 }
 
-struct problem * csr_set_problem (char *values, npy_intp *n_indices,
+struct problem * liblinear_csr_set_problem (char *values, npy_intp *n_indices,
 	char *indices, npy_intp *n_indptr, char *indptr, char *Y,
         npy_intp n_features, double bias, char *sample_weight) {
 
@@ -168,7 +168,7 @@
     }
 
     problem->y = (double *) Y;
-    problem->x = csr_to_sparse((double *) values, n_indices, (int *) indices,
+    problem->x = liblinear_csr_to_sparse((double *) values, n_indices, (int *) indices,
 			n_indptr, (int *) indptr, bias, n_features);
     problem->bias = bias;
     problem->sample_weight = sample_weight;
@@ -183,7 +183,7 @@
 
 
 /* Create a paramater struct with and return it */
-struct parameter *set_parameter(int solver_type, double eps, double C,
+struct parameter *liblinear_set_parameter(int solver_type, double eps, double C,
                                 npy_intp nr_weight, char *weight_label,
                                 char *weight, int max_iter, unsigned seed, 
                                 double epsilon)
@@ -204,17 +204,17 @@
     return param;
 }
 
-void copy_w(void *data, struct model *model, int len)
+void liblinear_copy_w(void *data, struct model *model, int len)
 {
     memcpy(data, model->w, len * sizeof(double)); 
 }
 
-double get_bias(struct model *model)
+double liblinear_get_bias(struct model *model)
 {
     return model->bias;
 }
 
-void free_problem(struct problem *problem)
+void liblinear_free_problem(struct problem *problem)
 {
     int i;
     for(i=problem->l-1; i>=0; --i) free(problem->x[i]);
@@ -222,7 +222,7 @@
     free(problem);
 }
 
-void free_parameter(struct parameter *param)
+void liblinear_free_parameter(struct parameter *param)
 {
     free(param);
 }
@@ -237,7 +237,7 @@
 }
 
 /* provide convenience wrapper */
-void set_verbosity(int verbosity_flag){
+void liblinear_set_verbosity(int verbosity_flag){
     if (verbosity_flag)
         set_print_string_function(&print_string_stdout);
     else
